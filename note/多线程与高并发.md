# 多线程与高并发1

进程 线程 协程

线程是进程的最小执行单元

一个程序里不同的执行路径可以理解为线程

---



启动线程的3种方法：

继承Thread并重写run方法

实现Runnable接口并重写run方法

通过lambda方法来启动   或者   通过线程池Executor.newCachedThread来进行启动线程

---



yield让出CPU并进入等待状态

t1线程里面调用t2.join()，会去执行t2，搞定之后回来继续执行t1

![多线程状态转移图 (1)](https://user-images.githubusercontent.com/17522733/97427594-14dd7f00-1915-11eb-90a6-17b69d8f4f34.png)

不要尝试去手动关闭线程，要让其正常结束

出现异常的时候正常会释放锁，所以需要格外小心，以免一个线程的脏数据在异常后被另一个线程读到

---



synchronized的底层实现：

JDK早期的时候是重量级的，需要调用OS的方法

后来做了改进，锁升级的概念：

- 如果当前只有一个线程想要对某个对象占用锁的话，直接在该对象的头部markword记录这个线程的ID，此为偏向锁。若同一把锁重入，就可以很方便地检查markword中记录的ID是否和自己一样，一样的话就直接执行，很快速方便。

- 如果有线程争用，则升级为自旋锁，等待的线程会反复查询该对象的锁是否已经被释放。

- 在自旋查询10次以后，升级为重量级锁，调用OS的方法，进入到等待队列中。这个线程就进入了等待状态，不占用CPU资源。

---

什么时候使用自旋锁更好？

自旋锁不会调用OS的方法，一直处于用户态而不进入内核态，但会占用CPU的资源

因此对于执行时间长的任务建议使用OS锁，也就是synchronized。

对于执行时间短的任务可以使用自旋锁，但是需要保证等待的任务数不能过多，否则会CPU会受不了。

总结：

- 加锁的代码执行时间长，线程数多，使用重量级锁synchronized。  
- 加锁的代码任务执行时间短，线程数少，使用自旋锁。

---

# 多线程与高并发2

volatile作用：

- 保证线程可见性 
- 禁止指令重排序

单例模式，懒汉生成法，要保证线程安全【双重检查】：

```java
public class test{
    private static volatile test INSTANCE; //要加volatile，原因解释在下方
    private test(){}
    public getInstance(){
        if(INSTANCE==null){	//判断的时候先不加锁
            synchronized (test.class){
                if(INSTANCE==null){	//上一次判断后，要加锁，在new之前，看看在此期间是否有被别的线程抢占了锁并已经new出来了对象
                    INSTANCE=new test();
                }
            }
        }
        return INSTANCE;	//返回单例
    }
    public void someFunctions(){
        System.out.println("some functions.");
    }
    public static void main(String[] args){
        for(int i = 0; i<100; i++){
            new Thread(()->{
                System.out.println(test.getInstance().hashcode());
            }).start();
        }
    }
}
```

问题：双重检查写法的单例模式是否要加volatile？

答案：要的。

INSTANCE=new test();这一句话在JVM中有三个步骤：1. 申请内存（带有默认值）。2. 设置成员的值。3. 让引用指向内存的地址。

在不加volatile的情况下，上述的第2第3个步骤可能会进行指令重拍，也就是：申请内存->引用指向内存地址->设置成员的值。

在超高并发的场景下，线程A在new的过程中申请了带有默认值的内存，并把引用指向了该地址，还没来得及修改成员的值。此时线程B查看INSTANCE不为空，直接返回该单例并使用。在这种情况下，线程B拿到的成员的值是不对的，因为线程A还没有正确地初始化它。

加了volatile之后指令重排序不被允许，那么线程A在new的过程中就可以保证成员的值被正确初始化后才赋值给引用，就不会出现上述的问题了。

结论：双重检查写法的单例模式要加volatile。



---

synchronized优化

锁的细化，只加在需要锁的那部分代码。

如果synchronized对某个对象进行锁，那么建议那个对象添加修饰词final，以避免出现对象引用变化的情况。

不要用String类型来作为锁的对象。

---

CAS compare and swap/set 

无锁优化 或者叫 乐观锁。

AtomicInteger可以实现。

ABA问题解决：加版本号。修改一次版本号加一，检查的时候包括值本身和版本号。AtomicStampedReference类可以做到。

其实对于基本数据类型并没有问题，对于引用类型需要留意。

---

# 多线程与高并发3

LongAdder 分段锁。

ReentrantLock的使用可以替代synchronized：在原来使用synchronized(this)的地方换成reentrantLock.lock()，然后记得最后要reentrantLock.unlock()。同时要注意把lock()写在try里面，unlock()写在finally里面。以避免出现异常而无法正常释放锁。

ReentrantLock有一些比synchronized要强大的地方，比如：

- 可以尝试锁，自行决定等待锁时间：

  ```java
  Lock lock = new ReentrantLock();
  try {
      lock.tryLock(6, TimeUnit.MILLISECONDS);
  } catch (InterruptedException e) {
      e.printStackTrace();
  }finally {
      lock.unlock();
  }
  ```

- 可以被打断的加锁

  ```java
  Lock lock = new ReentrantLock();
  try {
      lock.lockInterruptibly();
  } catch (InterruptedException e) {
      e.printStackTrace();
  }finally {
      lock.unlock();
  }
  ```

- 可以实现公平锁：即先到先得，最后来的锁不能马上抢到对象，而是要进入等待队列中排队

  ```java
  Lock lock1 = new ReentrantLock(true);
  ```

---

CyclicBarrier

一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。

应用场景
在某种需求中，比如一个大型的任务，常常需要分配好多子任务去执行，只有当所有子任务都执行完成时候，才能执行主任务，这时候，就可以选择CyclicBarrier了。具体地，一个请求过来之后需要先进行数据库操作+文件操作+计算操作，这三者可以使用三个线程来同步执行，当这三个任务都执行完成后，执行一个渲染页面任务，此时可以在前三者的任务代码中调用CyclicBarrier的await()方法，然后把最后一个任务内容写在CyclicBarrier的Runnable里面。

> CyclicBarrier好比一扇门，默认情况下关闭状态，堵住了线程执行的道路，直到所有线程都就位，门才打开，让所有线程一起通过。

```java
CyclicBarrier barrier = new CyclicBarrier(3, new Runnable() {
    @Override
    public void run() {
        System.out.println("run application");		//主任务
    }
});

Runnable runnable = new Runnable() {				//子任务
    @Override
    public void run() {
        try {
            System.out.println(Thread.currentThread().getName());
            barrier.await();						//子任务中await一次CyclicBarrier
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (BrokenBarrierException e) {
            e.printStackTrace();
        }
    }
};

for (int i = 0; i < 3; i++) {
    new Thread(runnable,"Thread"+i).start();
    try {
        Thread.sleep(100);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
}
```

---

读写锁ReadWriteLock

对于一些读操作频繁而写操作不频繁的业务来说有巨大的性能提升。由ReentrantReadWriteLock类提供。

```java
public static void main(String[] args) {
    ReentrantLock lock = new ReentrantLock();
    ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();
    Lock readLock = readWriteLock.readLock();
    Lock writeLock = readWriteLock.writeLock();
    for (int i = 0; i < 20; i++) {
        new Thread(()->read(readLock)).start();		//这里传入readLock就会迅速执行完毕，若传入lock则会有漫长的等待
    }
    for (int i = 0; i < 2; i++) {
        new  Thread(()->write(writeLock)).start();
    }
}

public static void read(Lock lock) {
    lock.lock();
    try {
        System.out.println("read");
        Thread.sleep(1000);
    } catch (InterruptedException e) {
        e.printStackTrace();
    } finally {
        lock.unlock();
    }
}

public static void write(Lock lock) {
    lock.lock();
    try {
        System.out.println("write");
        Thread.sleep(1000);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }finally {
        lock.unlock();
    }
}
```

---

semaphore

可以用来【限流】。

无论有多少个线程活跃着，能运行的（获取到锁）只有permits限定的这么多个。每次acquire就会使得permits减一，每次release就会加一。

可以形象地理解成车道和收费站的关系。

---

# 多线程与高并发4

> [淘宝面试题1](https://github.com/ogugugugugua/Java-Notes/tree/2237b94422e32529f6a1825a3023975be95c560c/code/multiThread/src/com/interviewExercises/ex1)：实现一个容器，提供两个方法add size，写两个线程，线程1添加10个元素到容器中，线程2实现监控元素的个数，当个数到5个时，线程2给出提示并结束

解法详解：

- T01并不能用，因为线程1更改的内容对于线程2来说并不可见。
- T02和T03本质上属于在T01基础上增加了volatile关键字，虽然可行但是很奇怪：volatile修饰的是指向内存地址的指针，而这个指针是不会随着内存中值的修改而变化的，所以并不能合理地解释为什么线程1修改的值能够及时让线程2感知到。暂时放下不表。
- T04也不能用。因为notify不释放锁，所以线程1即使唤醒了线程2，但是并没有释放掉锁，线程2只能等着。
- T05是真正可用的版本，需要背下来，这是最基础原始的写法。线程1在容器到达指定size的时候通知线程2的同时需要把自己停掉，等线程2执行完之后再唤醒线程1。
- T06与T05在思想上高度雷同，但是使用了两个CountDownLatch这个工具，使得原来的wait方法变成了latch.wait，原来的notify方法变成了latch.countDown方法。
- T07是最简洁的版本，同样与T05在思想上高度雷同，使用了LockSupport工具，使用park方法代替wait来停住自己，使用unpark方法代替notify来唤醒另外一个线程。





> [淘宝面试题2](https://github.com/ogugugugugua/Java-Notes/tree/2237b94422e32529f6a1825a3023975be95c560c/code/multiThread/src/com/interviewExercises/ex2)：写一个固定容量同步容器，拥有put和get方法，以及getCount方法，能够支持2个生产者线程和10个消费者线程的阻塞调用。

- 这是经典的题目，需要直接背好解题。
- 需要注意的是需要使用while来判断当前size和最大/最小限制的关系。
- T01是比较高效的版本，由于引入了Condition这个工具，只会唤醒指定线程队列里面的等待队列。

---

LockSupport

unpark可以在park前调用，以失效即将到来的park。可以看出比wait和notify更灵活。

---

Condition的本质就是等待队列！

---

AQS	AbstractQueuedSynchronizer 是很重要的类，需要仔细阅读源码

模板方法 钩子函数; template method, callback function



# 多线程与高并发5

varHandle可以用于获取某个对象的引用，其具有两个有意思的特点：1.可以对普通属性进行原子操作。2.比反射快，直接操纵二进制码

---

ThreadLocal类允许我们创建只能被同一个线程读写的变量。因此，如果一段代码含有一个ThreadLocal变量的引用，即使两个线程同时执行这段代码，它们也无法访问到对方的ThreadLocal变量。

数据库声明式事务可以用到，以保证多个事务用到的是同一个连接：在单线程应用程序中可能会维持一个全局的数据库连接，并在程序启动时初始化这个连接对象，从而避免在调用每个方法时都要传递一个Connection对象。由于JDBC的连接对象不一定是线程安全的，因此在多线程应用程序在没有协同的情况下使用全局变量时，就不是线程安全的。通过将JDBC的连接保存到ThreadLocal对象中，每个线程都会拥有属于自己的连接：

```java 
private static ThreadLocal<Connection> connectionHolder = new ThreadLocal<Connection>(){
    @Override
    public Connection initialValue(){
        return DriverManager.getConnection(DB_URL);
    }
};

public static Connection getConnection(){
    return connectionHolder.get();
}
```

当某个线程首次调用ThreadLocal.get方法时，就会调用initialValue来获取初始值。

从概念上看，可以将ThreadLocal<T> 看成包含了Map<Thread, T>对象，其中保存了特定于该线程的值。

如果需要将一个单线程应用程序移植到多线程环境中，通过将共享的全局变量转换为ThreadLocal对象，可以维持线程安全性。

---

Java的四种引用：强软弱虚

普通的引用就是强引用。被强引用的对象显然不会被GC回收

软引用SoftReference。当一个内存被软引用指向，只有当空间不够用的时候才会被回收。用途：可以用在缓存，比如缓存一个大图片。

弱引用WeakReference。只要遇到GC就会被回收。一般用在容器里。如WeakHashMap。一个典型的应用就是ThreadLocal。

虚引用PhantomReference管理堆外内存。

----

# 多线程与高并发6

容器在物理结构上只有两种：连续存储（数组）和非连续存储（链表）

按照编排方式可以按下图的方式进行分离：【背好】

![](https://user-images.githubusercontent.com/17522733/97811254-9583de80-1c79-11eb-87be-708336293afd.png)

这个BlockingQueue阻塞队列主要服务于高并发的任务。

Deque是双端队列。

Vector和HashTable的很多操作都加了synchronized，所以在一定程度上性能一般般。

---

HashMap没有加synchronized，所以它不是线程安全的。

通过Collections.synchronizedMap(new HashMap<>());可以获得线程安全的HashMap。在底层实现上依旧是加了synchronized。

目前来说HashTable和Vector基本不用。

现在有一个**读效率**更高的ConcurrentHashMap。

**注意**：上述的这些Map并不是绝对的替代关系，因为CAS和synchronized没有绝对的优劣之分，要根据实际情况下并发量的大小和并发代码的执行时间进行具体的判断。

---

注意：即使使用了线程安全的容器比如vector，依然有可能会出现问题，比如我们调用了synchronized的size方法判断大小之后，再调用synchronized的remove方法去除元素，但是中间可能会有别的线程对容器进行干预，也就是说两个原子操作之间并不能保证原子性。

解决办法：使用ConcurrentLinkedQueue（对应remove的是poll方法）。以后对于单个元素的集合，尽量考虑Queue集合而不是List集合，因为其对高并发具有更好的支持。

查看源码可以发现ConcurrentLinkedQueue的底层原子性是通过CAS来实现的，所以其效率很高。

---

TreeMap使用红黑树实现，内部已排序，在查找的时候效率高。

ConcurrentSkipListMap支持高并发而且排序。通过跳表来实现。（代替了不存在的ConcurrentTreeMap）

跳表的结构是这样的：

![](https://www.xstnet.com/uploads/images/2019-09/b7ec1e2fa4791f9a16e5bd661fc50040.png)

最底层基础的还是一个链表结构，然后在其上层逐步进行抽象，只拿下层的若干个关键节点，这样有利于减少查询次数。

---

CopyOnWriteList / CopyOnWriteSet 写时复制

应用场景：写得少，读得多。（因为这个结构在读的时候不加锁，写的时候进行一波复制）

这个东西的源码非常容易理解：

```java
//添加一个元素：Appends the specified element to the end of this list.
public boolean add(E e) {		
    final ReentrantLock lock = this.lock;
    lock.lock();				//锁上
    try {
        Object[] elements = getArray();	
        int len = elements.length;	//获取原数组长度
        Object[] newElements = Arrays.copyOf(elements, len + 1);	//复制一个新数组，并指定长度加一
        newElements[len] = e;		//设定最新添加的元素在末位
        setArray(newElements);		//更改引用
        return true;
    } finally {
        lock.unlock();				//释放锁
    }
}
```

```java
//删除一个元素Removes the element at the specified position in this list. Shifts any subsequent elements to the left
public E remove(int index) {	
    final ReentrantLock lock = this.lock;
    lock.lock();						//锁上
    try {
        Object[] elements = getArray();
        int len = elements.length;			//获取原数组长度
        E oldValue = get(elements, index);	//获取被删除的元素
        int numMoved = len - index - 1;		//计算index后方需要移动的元素个数
        if (numMoved == 0)					//index后方需要移动的元素个数为0，即删除了最后一个元素
            setArray(Arrays.copyOf(elements, len - 1));	//直接把整个数组复制到新的数组里并忽略最后一位即可
        else {
            Object[] newElements = new Object[len - 1];	//先new一个新的数组
            System.arraycopy(elements, 0, newElements, 0, index);	//复制前半部分
            System.arraycopy(elements, index + 1, newElements, index, numMoved);	//复制后半部分
            setArray(newElements);			//指向新的引用								
        }
        return oldValue;					//返回被删除的元素
    } finally {
        lock.unlock();						//释放锁
    }
}
```

---

BlockingQueue 阻塞队列

重点在“阻塞”上。有以下几种：

DelayBlockingQueue可以实现在时间上的排序。ArrayBlockingQueue有界的。LinkedBlockingQueue无界的。SynchronousQueue一般用于线程间传递任务。TransferQueue也同于线程间传递任务，可以传多个。

---

关于Queue这个类的方法，一般常用offer来增加，用peek来查看顶端，poll来查看并删除顶端。

对于BlockingQueue这个接口而言，会有以下的方法：

1. 添加元素：

- add：有位置则增加，如果满了就会报错
- offer：有位置则增加，如果满了就会返回false
- put：有位置则增加，如果满了就会阻塞到有位置再增加

2. 删除元素：

- remove：有对应元素则删除并返回true，否则返回false
- poll(long timeout, TimeUnit unit)：返回并删除队列的头节点，等待时间超过unit之后就会有中断异常
- take：返回并删除队列的头结点，如果队列为空则阻塞直到有值可以返回

显然这种BlockingQueue就是天生对线程安全的生产着消费者模型

比如我们可以看LinkedBlockingQueue的put方法源码：

```java
//类成员
/** Lock held by take, poll, etc */
private final ReentrantLock takeLock = new ReentrantLock();

/** Wait queue for waiting takes */
private final Condition notEmpty = takeLock.newCondition();

/** Lock held by put, offer, etc */
private final ReentrantLock putLock = new ReentrantLock();

/** Wait queue for waiting puts */
private final Condition notFull = putLock.newCondition();



/**
 * Inserts the specified element at the tail of this queue, waiting if
 * necessary for space to become available.
 *
 * @throws InterruptedException {@inheritDoc}
 * @throws NullPointerException {@inheritDoc}
 */
public void put(E e) throws InterruptedException {
    if (e == null) throw new NullPointerException();
    // Note: convention in all put/take/etc is to preset local var
    // holding count negative to indicate failure unless set.
    int c = -1;
    Node<E> node = new Node<E>(e);	//即将放进去的Node节点
    final ReentrantLock putLock = this.putLock;
    final AtomicInteger count = this.count;//当前元素个数
    putLock.lockInterruptibly();	//锁上
    try {
        while (count.get() == capacity) {
            notFull.await();		//满了就等待
        }
        enqueue(node);				//放进去
        c = count.getAndIncrement(); //当前元素个数是之前个数+1
        if (c + 1 < capacity)
            notFull.signal();		//加完之后还没满，可以让其他等待着的线程继续添加元素
    } finally {
        putLock.unlock();			//解锁
    }
    if (c == 0)
        signalNotEmpty();			//加完之后就刚好不空了，唤醒那些等待着take的线程来取元素
}
```

而ArrayBlockingQueue可以指定容量capacity，满了的时候如果使用put方法就会阻塞，同理满了的时候使用add就会抛出异常。

---

**总结一下**：

- Queue和List这两个集合的区别主要在于对于多线程的支持，提供了很多友好的API，比如offer，peek，poll。
- Queue的子类BlockingQueue又添加了一些与阻塞相关的API，比如take，put。

---

还有几个特殊一些的BlockingQueue：

**DelayQueue**可以按照在里面等待的时间进行排序。本质上使用的是PriorityQueue，应用场景：按照时间进行任务调度。

**SynchrnousQueue**的使用场景类似于Exchanger。需要有一个线程在阻塞着等take拿数据时候，才可以另一个线程往里面put放数据，否则无法放进去。内部无法存储元素，当要添加元素的时候，需要阻塞。

**LinkedTransferQueue**可以算是 `LinkedBolckingQueue` 和 `SynchronousQueue` 和合体。`LinkedTransferQueue`是 `SynchronousQueue` 和 `LinkedBlockingQueue` 的合体，性能比 `LinkedBlockingQueue` 更高（没有锁操作），比 `SynchronousQueue`能存储更多的元素。

当 `put` 时，如果有等待的线程，就直接将元素 “交给” 等待者， 否则直接进入队列。	

`put`和 `transfer` 方法的区别是，put 是立即返回的， transfer 是阻塞等待消费者拿到数据才返回。`transfer`方法和 `SynchronousQueue`的 put 方法类似。

> 作者：莫那一鲁道
> 链接：https://www.jianshu.com/p/ae6977886cec
> 来源：简书
> 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。